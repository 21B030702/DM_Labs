{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "aIdfHfD3kzQs",
        "outputId": "4a3adc4a-8cc8-412f-8c68-6c4d020fc36a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   PassengerId\\tSurvived\\tPclass\\tName\\tSex\\tAge\\tSibSp\\tParch\\tTicket\\tFare\\tCabin\\tEmbarked\n",
            "1\\t0\\t3\\tBraund      Mr. Owen Harris\\tmale\\t22\\t1\\t0\\tA/5 21171\\t7...                                        \n",
            "2\\t1\\t1\\tCumings     Mrs. John Bradley (Florence Briggs Thayer)\\tf...                                        \n",
            "3\\t1\\t3\\tHeikkinen   Miss. Laina\\tfemale\\t26\\t0\\t0\\tSTON/O2. 31012...                                        \n",
            "4\\t1\\t1\\tFutrelle    Mrs. Jacques Heath (Lily May Peel)\\tfemale\\t3...                                        \n",
            "5\\t0\\t3\\tAllen       Mr. William Henry\\tmale\\t35\\t0\\t0\\t373450\\t8....                                        \n",
            "                        PassengerId\\tSurvived\\tPclass\\tName\\tSex\\tAge\\tSibSp\\tParch\\tTicket\\tFare\\tCabin\\tEmbarked\n",
            "152\\t1\\t1\\tPears          Mrs. Thomas (Edith Wearne)\\tfemale\\t22\\t1\\t0\\...                                        \n",
            "153\\t0\\t3\\tMeo            Mr. Alfonzo\\tmale\\t55.5\\t0\\t0\\tA.5. 11206\\t8....                                        \n",
            "154\\t0\\t3\\tvan Billiard   Mr. Austin Blyler\\tmale\\t40.5\\t0\\t2\\tA/5. 851...                                        \n",
            "155\\t0\\t3\\tOlsen          Mr. Ole Martin\\tmale\\t\\t0\\t0\\tFa 265302\\t7.31...                                        \n",
            "156\\t0\\t1\\tWilliams       Mr. Charles Duane\\tmale\\t51\\t0\\t1\\tPC 17597\\t...                                        \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 156 entries, 1\t0\t3\tBraund to 156\t0\t1\tWilliams\n",
            "Data columns (total 1 columns):\n",
            " #   Column                                                                           Non-Null Count  Dtype \n",
            "---  ------                                                                           --------------  ----- \n",
            " 0   PassengerId\tSurvived\tPclass\tName\tSex\tAge\tSibSp\tParch\tTicket\tFare\tCabin\tEmbarked  156 non-null    object\n",
            "dtypes: object(1)\n",
            "memory usage: 2.4+ KB\n",
            "None\n",
            "PassengerId\\tSurvived\\tPclass\\tName\\tSex\\tAge\\tSibSp\\tParch\\tTicket\\tFare\\tCabin\\tEmbarked    0\n",
            "dtype: int64\n",
            "PassengerId\\tSurvived\\tPclass\\tName\\tSex\\tAge\\tSibSp\\tParch\\tTicket\\tFare\\tCabin\\tEmbarked    object\n",
            "dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAnswers to the questions:\\n1)Load a CSV file using pd.read_csv().\\n2)info() provides column names, non-null counts, and data types.\\n3)Identify missing values using isnull().sum().\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#Exercise 1: Loading Data with Pandas\n",
        "'''\n",
        "Questions:\n",
        "How do you load a CSV file into a Pandas DataFrame?\n",
        "What information does the info() function provide about the dataset?\n",
        "How can you identify missing values in the dataset?\n",
        "'''\n",
        "import pandas as pd\n",
        "df = pd.read_csv('titanic.csv')\n",
        "\n",
        "#Use head(), tail(), and info() to inspect the dataset:\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.info())\n",
        "\n",
        "#Check for missing values and data types:\n",
        "print(df.isnull().sum())\n",
        "print(df.dtypes)\n",
        "\n",
        "'''\n",
        "Answers to the questions:\n",
        "1)Load a CSV file using pd.read_csv().\n",
        "2)info() provides column names, non-null counts, and data types.\n",
        "3)Identify missing values using isnull().sum().\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise 2: Handling Missing Data\n",
        "# Загрузка данных\n",
        "df = pd.read_csv('titanic.csv', sep='\\t')\n",
        "\n",
        "# 1. Идентификация пропущенных значений\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Пропущенные значения в каждом столбце:\\n\", missing_values)\n",
        "\n",
        "# 2. Удаление строк с пропущенными значениями\n",
        "df_dropped = df.dropna()\n",
        "print(\"\\nДанные после удаления строк с пропущенными значениями:\\n\", df_dropped.head())\n",
        "\n",
        "# 3. Заполнение пропусков средним значением для числовых данных\n",
        "df_filled_mean = df.copy()\n",
        "df_filled_mean['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "df_filled_mean['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)  # Заполнение модой для категорий\n",
        "\n",
        "print(\"\\nДанные после заполнения средним значением (и модой для 'Embarked'):\\n\", df_filled_mean.head())\n",
        "\n",
        "# 4. Прямое заполнение пропусков (forward fill)\n",
        "df_ffill = df.fillna(method='ffill')\n",
        "print(\"\\nДанные после прямого заполнения (ffill):\\n\", df_ffill.head())\n",
        "\n",
        "# 5. Обратное заполнение пропусков (backward fill)\n",
        "df_bfill = df.fillna(method='bfill')\n",
        "print(\"\\nДанные после обратного заполнения (bfill):\\n\", df_bfill.head())\n",
        "'''\n",
        "Answers to the questions:\n",
        "1)Strategy could be filling with mean, median, or dropping based on data context.\n",
        "2)Filling values retains rows, while dropping may remove potentially useful data.\n",
        "3)Drop rows if missing data is significant and cannot be reliably imputed.\n",
        "'''"
      ],
      "metadata": {
        "id": "CJ8qIIvnmdPZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fa061347-f7b5-4cb8-8e5f-c25a7c4a44f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пропущенные значения в каждом столбце:\n",
            " PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age             30\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          125\n",
            "Embarked         1\n",
            "dtype: int64\n",
            "\n",
            "Данные после удаления строк с пропущенными значениями:\n",
            "     PassengerId  Survived  Pclass  \\\n",
            "1             2         1       1   \n",
            "3             4         1       1   \n",
            "6             7         0       1   \n",
            "10           11         1       3   \n",
            "11           12         1       1   \n",
            "\n",
            "                                                 Name     Sex   Age  SibSp  \\\n",
            "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
            "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
            "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
            "\n",
            "    Parch    Ticket     Fare Cabin Embarked  \n",
            "1       0  PC 17599  71.2833   C85        C  \n",
            "3       0    113803  53.1000  C123        S  \n",
            "6       0     17463  51.8625   E46        S  \n",
            "10      1   PP 9549  16.7000    G6        S  \n",
            "11      0    113783  26.5500  C103        S  \n",
            "\n",
            "Данные после заполнения средним значением (и модой для 'Embarked'):\n",
            "    PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "\n",
            "Данные после прямого заполнения (ffill):\n",
            "    PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   C85        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500  C123        S  \n",
            "\n",
            "Данные после обратного заполнения (bfill):\n",
            "    PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   C85        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250  C123        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   E46        S  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-43d5fe6a79c5>:21: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df_ffill = df.fillna(method='ffill')\n",
            "<ipython-input-3-43d5fe6a79c5>:25: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df_bfill = df.fillna(method='bfill')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAnswers to the questions:\\n1)Strategy could be filling with mean, median, or dropping based on data context.\\n2)Filling values retains rows, while dropping may remove potentially useful data.\\n3)Drop rows if missing data is significant and cannot be reliably imputed.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "# Загрузка данных\n",
        "df = pd.read_csv('titanic.csv', sep='\\t')\n",
        "\n",
        "# 1. Нормализация числовых данных с использованием Min-Max Scaling\n",
        "scaler = MinMaxScaler()\n",
        "df[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])\n",
        "\n",
        "# если нужна стандартизация (Z-score), можно заменить на:\n",
        "# standard_scaler = StandardScaler()\n",
        "# df[['Age', 'Fare']] = standard_scaler.fit_transform(df[['Age', 'Fare']])\n",
        "\n",
        "# 2. Кодирование категориальных переменных с использованием One-Hot Encoding\n",
        "df_encoded = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "\n",
        "df_encoded['Age'] = pd.to_numeric(df_encoded['Age'], errors='coerce')  # Преобразование в числовой тип, ошибки будут заменены на NaN\n",
        "df_encoded['Age'].fillna(df_encoded['Age'].mean(), inplace=True)  # Заполнение пропусков средним значением\n",
        "\n",
        "# 3. Бининг (разбиение на категории) возраста\n",
        "# Разделение возраста на 5 категорий: 'Very Young', 'Young', 'Middle Aged', 'Old', 'Very Old'\n",
        "df_encoded['Age_binned'] = pd.cut(df_encoded['Age'], bins=5, labels=['Very Young', 'Young', 'Middle Aged', 'Old', 'Very Old'])\n",
        "\n",
        "# Вывод преобразованных данных\n",
        "print(df_encoded.head())\n",
        "\n",
        "'''\n",
        "Answers to the questions:\n",
        "1)Normalization scales data between 0-1, while standardization centers it around the mean (0).\n",
        "2)One-hot encoding converts categorical data into binary vectors.\n",
        "3)Binning helps simplify continuous data into discrete categories for easier analysis.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "VgTki7iCp2dr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "74dc6eab-b046-4584-d5f0-9798d5572588"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name       Age  SibSp  Parch  \\\n",
            "0                            Braund, Mr. Owen Harris  0.301696      1      0   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  0.529714      1      0   \n",
            "2                             Heikkinen, Miss. Laina  0.358700      0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  0.486960      1      0   \n",
            "4                           Allen, Mr. William Henry  0.486960      0      0   \n",
            "\n",
            "             Ticket      Fare Cabin  Sex_male  Embarked_Q  Embarked_S  \\\n",
            "0         A/5 21171  0.001951   NaN      True       False        True   \n",
            "1          PC 17599  0.251837   C85     False       False       False   \n",
            "2  STON/O2. 3101282  0.004585   NaN     False       False        True   \n",
            "3            113803  0.180878  C123     False       False        True   \n",
            "4            373450  0.005073   NaN      True       False        True   \n",
            "\n",
            "    Age_binned  \n",
            "0        Young  \n",
            "1  Middle Aged  \n",
            "2        Young  \n",
            "3  Middle Aged  \n",
            "4  Middle Aged  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAnswers to the questions:\\n1)Normalization scales data between 0-1, while standardization centers it around the mean (0).\\n2)One-hot encoding converts categorical data into binary vectors.\\n3)Binning helps simplify continuous data into discrete categories for easier analysis.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise 4: Feature Engineering\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "df = pd.read_csv('titanic.csv', sep='\\t')\n",
        "\n",
        "# Преобразование и заполнение пропущенных значений для 'Age' и 'Fare'\n",
        "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
        "df['Fare'] = pd.to_numeric(df['Fare'], errors='coerce')\n",
        "\n",
        "# Использование импьютатора для заполнения NaN значений\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df[['Age', 'Fare']] = imputer.fit_transform(df[['Age', 'Fare']])\n",
        "\n",
        "# Создание полиномиальных признаков\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "poly_features = poly.fit_transform(df[['Age', 'Fare']])\n",
        "df_poly = pd.DataFrame(poly_features, columns=['Age', 'Fare', 'Age^2', 'Age*Fare', 'Fare^2'])\n",
        "\n",
        "# Добавление новых признаков к исходным данным\n",
        "df = pd.concat([df, df_poly], axis=1)\n",
        "\n",
        "# 2. Извлечение признаков из даты\n",
        "# Предположим, у нас есть столбец с датой, например, 'Date'\n",
        "# df['Date'] = pd.to_datetime(df['Date'])  # Пример преобразования столбца в формат даты\n",
        "# df['Year'] = df['Date'].dt.year\n",
        "# df['Month'] = df['Date'].dt.month\n",
        "# df['Day'] = df['Date'].dt.day\n",
        "\n",
        "# 3. Использование предметных знаний для создания признаков\n",
        "# Например, можно создать признак 'IsAlone', который определяет, путешествовал ли пассажир один\n",
        "if 'SibSp' in df.columns and 'Parch' in df.columns:\n",
        "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
        "else:\n",
        "    print(\"Столбцы 'SibSp' и/или 'Parch' отсутствуют в данных.\")\n",
        "\n",
        "print(df[['SibSp', 'Parch', 'FamilySize']].head())\n",
        "\n",
        "# Например, создание признака 'IsAlone'\n",
        "df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
        "\n",
        "# Вывод первых строк после создания новых признаков\n",
        "print(df.head())\n",
        "\n",
        "'''\n",
        "Answers to the questions\n",
        "1)New features can capture interactions or higher-order relationships.\n",
        "2)Date-based features allow capturing time-based trends in data.\n",
        "'''"
      ],
      "metadata": {
        "id": "7DDnef9hraqm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "dde2d28e-6882-4012-cf34-ad47ec002e0f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   SibSp  Parch  FamilySize\n",
            "0      1      0           2\n",
            "1      1      0           2\n",
            "2      0      0           1\n",
            "3      1      0           2\n",
            "4      0      0           1\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked   Age     Fare   Age^2  \\\n",
            "0      0         A/5 21171   7.2500   NaN        S  22.0   7.2500   484.0   \n",
            "1      0          PC 17599  71.2833   C85        C  38.0  71.2833  1444.0   \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  26.0   7.9250   676.0   \n",
            "3      0            113803  53.1000  C123        S  35.0  53.1000  1225.0   \n",
            "4      0            373450   8.0500   NaN        S  35.0   8.0500  1225.0   \n",
            "\n",
            "    Age*Fare       Fare^2  FamilySize  IsAlone  \n",
            "0   159.5000    52.562500           2        0  \n",
            "1  2708.7654  5081.308859           2        0  \n",
            "2   206.0500    62.805625           1        1  \n",
            "3  1858.5000  2819.610000           2        0  \n",
            "4   281.7500    64.802500           1        1  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAnswers to the questions\\n1)New features can capture interactions or higher-order relationships.\\n2)Date-based features allow capturing time-based trends in data.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise 5: Data Cleaning\n",
        "from scipy import stats\n",
        "\n",
        "# Загрузка данных\n",
        "df = pd.read_csv('titanic.csv', sep='\\t')\n",
        "\n",
        "# 1. Удаление дубликатов\n",
        "df_cleaned = df.drop_duplicates()\n",
        "\n",
        "# Проверка, были ли удалены дубликаты\n",
        "print(\"Дубликаты удалены:\", df.shape[0] - df_cleaned.shape[0], \"строк\")\n",
        "\n",
        "# 2. Обнаружение и удаление выбросов с использованием Z-score\n",
        "z_scores = stats.zscore(df_cleaned[['Age', 'Fare']])\n",
        "abs_z_scores = abs(z_scores)\n",
        "df_cleaned_no_outliers = df_cleaned[(abs_z_scores < 3).all(axis=1)]\n",
        "\n",
        "# Альтернатива: Использование метода межквартильного размаха (IQR)\n",
        "Q1 = df_cleaned[['Age', 'Fare']].quantile(0.25)\n",
        "Q3 = df_cleaned[['Age', 'Fare']].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "df_cleaned_no_outliers = df_cleaned[~((df_cleaned[['Age', 'Fare']] < (Q1 - 1.5 * IQR)) | (df_cleaned[['Age', 'Fare']] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "print(\"Выбросы удалены:\", df_cleaned.shape[0] - df_cleaned_no_outliers.shape[0], \"строк\")\n",
        "\n",
        "# 3. Исправление несоответствий в категориальных данных\n",
        "# Приведение значений категориальных столбцов к нижнему регистру для стандартизации\n",
        "df_cleaned_no_outliers['Sex'] = df_cleaned_no_outliers['Sex'].str.lower()\n",
        "df_cleaned_no_outliers['Embarked'] = df_cleaned_no_outliers['Embarked'].str.upper()\n",
        "\n",
        "# Проверка результатов\n",
        "print(df_cleaned_no_outliers.head())\n",
        "\n",
        "'''\n",
        "Answers to the questions\n",
        "1)Duplicates are handled with drop_duplicates().\n",
        "2)Outliers are detected with Z-score or IQR methods depending on data distribution.\n",
        "3)Categorical inconsistencies can be addressed by standardizing formats or merging similar categories.\n",
        "'''"
      ],
      "metadata": {
        "id": "4IxT5JgLsXd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "outputId": "4e115da2-722e-4745-9ffe-7821fcdd2f39"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Дубликаты удалены: 0 строк\n",
            "Выбросы удалены: 19 строк\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "5            6         0       3   \n",
            "\n",
            "                                           Name     Sex   Age  SibSp  Parch  \\\n",
            "0                       Braund, Mr. Owen Harris    male  22.0      1      0   \n",
            "2                        Heikkinen, Miss. Laina  female  26.0      0      0   \n",
            "3  Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0   \n",
            "4                      Allen, Mr. William Henry    male  35.0      0      0   \n",
            "5                              Moran, Mr. James    male   NaN      0      0   \n",
            "\n",
            "             Ticket     Fare Cabin Embarked  \n",
            "0         A/5 21171   7.2500   NaN        S  \n",
            "2  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3            113803  53.1000  C123        S  \n",
            "4            373450   8.0500   NaN        S  \n",
            "5            330877   8.4583   NaN        Q  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-706d625cf96d>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned_no_outliers['Sex'] = df_cleaned_no_outliers['Sex'].str.lower()\n",
            "<ipython-input-9-706d625cf96d>:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned_no_outliers['Embarked'] = df_cleaned_no_outliers['Embarked'].str.upper()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAnswers to the questions\\n1)Duplicates are handled with drop_duplicates().\\n2)Outliers are detected with Z-score or IQR methods depending on data distribution.\\n3)Categorical inconsistencies can be addressed by standardizing formats or merging similar categories.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise 6: Splitting Data into Training and Testing Sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Загрузка данных\n",
        "df = pd.read_csv('titanic.csv', sep='\\t')  # Укажите путь к вашему CSV-файлу\n",
        "\n",
        "# Предположим, что целевая переменная — это 'Survived', а остальные — признаки\n",
        "X = df.drop('Survived', axis=1)  # Признаки (фичи)\n",
        "y = df['Survived']  # Целевая переменная\n",
        "\n",
        "# 1. Разделение данных на обучающую и тестовую выборки (70-30)\n",
        "X_train_70, X_test_30, y_train_70, y_test_30 = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 2. Разделение данных на обучающую и тестовую выборки (80-20)\n",
        "X_train_80, X_test_20, y_train_80, y_test_20 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Проверка размеров выборок\n",
        "print(\"Размер обучающей выборки (70-30):\", X_train_70.shape, y_train_70.shape)\n",
        "print(\"Размер тестовой выборки (70-30):\", X_test_30.shape, y_test_30.shape)\n",
        "\n",
        "print(\"Размер обучающей выборки (80-20):\", X_train_80.shape, y_train_80.shape)\n",
        "print(\"Размер тестовой выборки (80-20):\", X_test_20.shape, y_test_20.shape)\n",
        "'''\n",
        "Answers to the questions\n",
        "1)Consider the balance between training data and generalization.\n",
        "2)A smaller training set may underfit, while a too-large set might not generalize well.\n",
        "'''"
      ],
      "metadata": {
        "id": "HKBgJ4RytJUb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "40832e33-5752-48b3-9cb2-b4fc812604cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер обучающей выборки (70-30): (109, 11) (109,)\n",
            "Размер тестовой выборки (70-30): (47, 11) (47,)\n",
            "Размер обучающей выборки (80-20): (124, 11) (124,)\n",
            "Размер тестовой выборки (80-20): (32, 11) (32,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAnswers to the questions\\n1)Consider the balance between training data and generalization.\\n2)A smaller training set may underfit, while a too-large set might not generalize well.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise 7: Data Preprocessing Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "df = pd.read_csv('titanic.csv', sep='\\t')\n",
        "\n",
        "# 1. Разделение данных на признаки и целевую переменную\n",
        "X = df.drop(columns=['Survived'])\n",
        "y = df['Survived']\n",
        "\n",
        "# 2. Разделение на тренировочные и тестовые выборки (70-30)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 3. Создание конвейера предобработки данных\n",
        "\n",
        "# Определение числовых и категориальных столбцов\n",
        "numeric_features = ['Age', 'Fare']\n",
        "categorical_features = ['Sex', 'Embarked']\n",
        "\n",
        "# Конвейер для числовых признаков: заполнение пропусков и масштабирование\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),  # Заполнение пропусков средним значением\n",
        "    ('scaler', StandardScaler())  # Масштабирование данных\n",
        "])\n",
        "\n",
        "# Конвейер для категориальных признаков: заполнение пропусков и One-Hot кодирование\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Объединение всех преобразований с помощью ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# 4. Интеграция конвейера предобработки с моделью (например, RandomForestClassifier)\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "# 5. Обучение модели\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Оценка модели\n",
        "score = pipeline.score(X_test, y_test)\n",
        "print(f\"Точность модели: {score:.2f}\")\n",
        "'''\n",
        "Answer to the questions:\n",
        "1)Pipelines streamline preprocessing and ensure consistency between training and testing.\n",
        "2)It allows the easy addition of more steps (e.g., feature encoding).\n",
        "'''"
      ],
      "metadata": {
        "id": "TPxmHVfWtbUU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e5d2a16c-2c3d-438c-c511-81f663c62304"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность модели: 0.74\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAnswer to the questions:\\n1)Pipelines streamline preprocessing and ensure consistency between training and testing.\\n2)It allows the easy addition of more steps (e.g., feature encoding).\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jMh-6vF1tPV3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}